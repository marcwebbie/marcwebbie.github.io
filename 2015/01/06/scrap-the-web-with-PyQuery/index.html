<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>Scrap The Web With PyQuery | Marcwebbie</title>
  <meta name="description" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="/css/style.css" />
  <meta name="generator" content="Marcwebbie">

  
  
  

  
</head>

<!--
<body class="post-template">
-->
<body class="home-template">
<div id="perspective" class="perspective effect-movedown">
  <div class="container">
    <!-- wrapper -->
    <div class="wrapper">

      <header class="site-head"  style="background: #24282b url(/img/img-bg.jpg) 0 -20%" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="/img/logo.svg" alt="Blog Logo"/></a> 
            <h1 class="blog-title">Marcwebbie</h1>
            <h2 class="blog-description"><button id="showMenu">Show Menu</button></h2>
        </div>
    </div>
</header>

      

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2015-01-06T22:59:30.000Z" itemprop="datePublished">
          Jan 6 2015
      </time>
    
    
    | 
    <a href='/tags/Programming/'>Programming</a>,
    
    <a href='/tags/Python/'>Python</a>,
    
    <a href='/tags/Scraping/'>Scraping</a>,
    
    <a href='/tags/WebMining/'>WebMining</a>
    
    
</span>
    <h1 class="post-title">Scrap The Web With PyQuery</h1>
    <section class="post-content">
      <p>In this article I will be showing how to do <a href="http://en.wikipedia.org/wiki/Web_scraping">Web Scraping</a> in Python using Pyquery. There is a lot of <a href="http://docs.python-guide.org/en/latest/scenarios/scrape/">tools</a> for webscraping using Python. The most well know tool is <a href="http://scrapy.org/">Scrapy</a>, Scrapy is a great tool, and you can find a lot of tutorials about it. Although Scrapy is a great tool, as of today Scrapy <a href="http://doc.scrapy.org/en/latest/faq.html#does-scrapy-work-with-python-3">doesn’t support Python 3</a> yet. Scrapy is also a framework, with a lot of functionalities and a particular directory structure that you should use. Those are the makor points that hold me back from using Scrapy for most of my web scraping.</p>
<p>Most of the time my Web Scraping code can be sumarized to the steps:</p>
<ol>
<li>Go to x url</li>
<li>Find elements “foo”, “bar”, etc</li>
<li>Build data from found elements</li>
</ol>
<p>For this kind of application, I only need one tool:</p>
<h2 id="Pyquery">Pyquery</h2>
<p><a href="https://github.com/gawel/pyquery/">PyQuery</a> lets you access webpage elements in using the DOM similar to the way <a href="http://jquery.com/">JQuery</a> do it. Check those examples:</p>
<h4 id="html"><code>html</code></h4>
<p>Suppose that the content of example.com is the html below:</p>
<figure class="highlight html"><figcaption><span>example1.html</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="title">ul</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="title">li</span>&gt;</span>foo<span class="tag">&lt;/<span class="title">li</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="title">li</span>&gt;</span>bar<span class="tag">&lt;/<span class="title">li</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="title">ul</span>&gt;</span></div></pre></td></tr></table></figure>

<h4 id="JQuery"><code>JQuery</code></h4>
<figure class="highlight javascript"><figcaption><span>example1.js</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// example from http://api.jquery.com/each/</span></div><div class="line">$( <span class="string">"li"</span> ).each(<span class="function"><span class="keyword">function</span><span class="params">( index )</span> </span>{</div><div class="line">  <span class="built_in">console</span>.log( $( <span class="keyword">this</span> ).text() );</div><div class="line">});</div></pre></td></tr></table></figure>

<h4 id="PyQuery"><code>PyQuery</code></h4>
<figure class="highlight python"><figcaption><span>example1.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery</div><div class="line">d = PyQuery(<span class="string">"example.com"</span>)</div><div class="line"><span class="keyword">for</span> li <span class="keyword">in</span> d(<span class="string">"li"</span>):</div><div class="line">    print(li.text)</div></pre></td></tr></table></figure>

<p><code>d</code> in our <code>example.py</code> works the same as our <code>$</code> at example.js. One big bonus is not having to use another library to download page content. PyQuery can fetch it for you:</p>
<pre><code><span class="variable">d =</span> PyQuery(<span class="string">"http://www.example.com"</span>)
</code></pre><p>Here <code>d</code> is a referencing the dom on the content of <code>www.example.com</code>.</p>
<p>Cool right? <strong>PyQuery</strong> has much of JQuery syntax and even some unique constructs. Most of the time you can test your constructs on your browser console and copy past the selectors string into your python code.</p>
<p>Mixing PyQuery with <a href="http://docs.python-requests.org/en/latest/">Requests</a> makes Web Scraping even more powerful. When the need comes to interact with the web page, like send forms, manage cookies and more, Requests + Pyquery will be the couple of tools you will need.</p>
<h2 id="Getting_started">Getting started</h2>
<p>We will create <code>fooscraper</code>. <code>fooscraper</code> will be a little tool that finds every hred links in a webpage and download the page that it points. Not very useful as an application but it will show you the idea behind PyQuery</p>
<p>The tools needed:</p>
<ul>
<li><a href="https://pypi.python.org/pypi/pip/">pip</a></li>
<li><a href="https://pypi.python.org/pypi/virtualenv">virtualenv</a></li>
</ul>
<h3 id="Create_and_activate_virtualenv">Create and activate virtualenv</h3>
<p>Let’s use a virtualenv for isolating work from the system:</p>
<pre><code>virtualenv scraping
<span class="built_in">cd</span> scraping
<span class="built_in">source</span> bin/activate
</code></pre><h4 id="Create_project_files">Create project files</h4>
<p>Now that our virtualenv active, let’s create our project files:</p>
<pre><code><span class="built_in">mkdir</span> fooscraper
<span class="keyword">cd</span> fooscraper
touch fooscraper.<span class="keyword">py</span>
touch tests.<span class="keyword">py</span>
</code></pre><h4 id="Install_PyQuery">Install PyQuery</h4>
<pre><code>pip <span class="operator"><span class="keyword">install</span> pyquery</span>
</code></pre><hr>
<h3 id="Scraping">Scraping</h3>
<h4 id="Step_1_-_Find_all_links_in_a_page">Step 1 - Find all links in a page</h4>
<p>Find all <code>&lt;a&gt;</code> links on the webpage at the given url and return them as a list of urls to resources:</p>
<figure class="highlight python"><figcaption><span>archive.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery</div><div class="line"><span class="comment">#...</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_links</span><span class="params">(url)</span>:</span></div><div class="line">    d = PyQuery(url)</div><div class="line">    <span class="keyword">return</span> [d(a).attr(<span class="string">"href"</span>) <span class="keyword">for</span> a <span class="keyword">in</span> d(<span class="string">"a"</span>)]</div></pre></td></tr></table></figure>

<h4 id="Step_2_-_Find_only_internal_links">Step 2 - Find only internal links</h4>
<p>Let’s make our find links code cleaner to get only internal links:</p>
<figure class="highlight python"><figcaption><span>archive.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_absolute</span><span class="params">(url)</span>:</span></div><div class="line">    <span class="keyword">return</span> bool(urlparse(url).netloc)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_links</span><span class="params">(url)</span>:</span></div><div class="line">    d = PyQuery(url)</div><div class="line">    <span class="keyword">return</span> [d(a).attr(<span class="string">"href"</span>) <span class="keyword">for</span> a <span class="keyword">in</span> d(<span class="string">"a"</span>)</div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> is_absolute(d(a).attr(<span class="string">"href"</span>))]</div></pre></td></tr></table></figure>

<h4 id="Step_3_-_Download_every_resouce_at_link_into_path">Step 3 - Download every resouce at link into path</h4>
<p>Save every resource located at path into a file inside given path:</p>
<figure class="highlight python"><figcaption><span>archive.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># previous snippets</span></div><div class="line"><span class="comment"># ...</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(url, link, directory)</span>:</span></div><div class="line">    resource_url = urljoin(url, link)</div><div class="line">    content = urlopen(resource_url)</div><div class="line">    filepath = path.join(directory, link)</div><div class="line">    <span class="keyword">with</span> open(filepath, <span class="string">"w"</span>) <span class="keyword">as</span> f:</div><div class="line">        f.write(content)</div><div class="line">    <span class="keyword">return</span> filepath</div></pre></td></tr></table></figure>

<h4 id="Step_4_-_Main_entry_to_download_all_links">Step 4 - Main entry to download all links</h4>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># previous snippets</span></div><div class="line"><span class="comment"># ...</span></div><div class="line"><span class="keyword">if</span> <span class="variable">__name__ =</span>= <span class="string">"__main__"</span>:</div><div class="line">    <span class="variable">parser =</span> argparse.ArgumentParser(<span class="variable">prog=</span><span class="string">"fooscraper"</span>)</div><div class="line">    parser.add_argument(<span class="string">"url"</span>, <span class="variable">help=</span><span class="string">"Url to look for links"</span>)</div><div class="line">    parser.add_argument(<span class="string">"-d"</span>, <span class="string">"--download"</span>, <span class="variable">action=</span><span class="string">"store_true"</span>,</div><div class="line">                        <span class="variable">help=</span><span class="string">"Url to look for links"</span>)</div><div class="line">    <span class="variable">args =</span> parser.parse_args()</div><div class="line">    <span class="comment">#</span></div><div class="line">    <span class="variable">download_dir =</span> <span class="string">"data"</span></div><div class="line">    <span class="keyword">if</span> not os.path.exists(download_dir):</div><div class="line">        os.makedirs(download_dir)</div><div class="line">    <span class="comment">#</span></div><div class="line">    <span class="variable">links =</span> find_links(args.url)</div><div class="line">    <span class="keyword">if</span> args.download:</div><div class="line">        for link <span class="keyword">in</span> find_links(args.url):</div><div class="line">            <span class="variable">dl_path =</span> download(args.url, <span class="variable">link=</span>link, <span class="variable">path=</span>download_dir)</div><div class="line">            print(<span class="string">"Saved file into {}"</span>.format(dl_path))</div></pre></td></tr></table></figure>

<p>You can run the code from terminal:</p>
<pre><code>fooscraper example.<span class="keyword">com</span>
</code></pre><p>or to download all links into a a given path</p>
<pre><code>fooscraper <span class="operator">-d</span> /tmp/save_dir example.com
</code></pre><h4 id="Async_downloads">Async downloads</h4>
<p>If you want to download the pages asynchronously, we can use a decorator</p>
<figure class="highlight python"><figcaption><span>decorators.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</div><div class="line"><span class="comment">#</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">async</span><span class="params">(f)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args, **kwargs)</span>:</span></div><div class="line">        thr = Thread(target=f, args=args, kwargs=kwargs)</div><div class="line">        thr.start()</div><div class="line">    <span class="keyword">return</span> wrapper</div></pre></td></tr></table></figure>

<p>Then apply the decorator to the Download Method:</p>
<figure class="highlight python"><figcaption><span>archive.py</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> decorators.py <span class="keyword">import</span> async</div><div class="line"><span class="comment"># previous snippets</span></div><div class="line"><span class="decorator">@async</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(url, link, directory)</span>:</span></div><div class="line">    resource_url = urljoin(url, link)</div><div class="line">    content = urlopen(resource_url)</div><div class="line">    filepath = path.join(directory, link)</div><div class="line">    <span class="keyword">with</span> open(filepath, <span class="string">"w"</span>) <span class="keyword">as</span> f:</div><div class="line">        f.write(content)</div><div class="line">    <span class="keyword">return</span> filepath</div></pre></td></tr></table></figure>

<h2 id="Summary">Summary</h2>
<p>Of course PyQuery is much more useful than that. I’ve been using it for a while now and it has fulfilled much of my needs in Web Scraping. Their<br><a href="https://pythonhosted.org/pyquery/index.html">documentation</a> is very concise and easy to read. Their code is also very clean. Bonus points if you read it at <a href="https://github.com/gawel/pyquery">Github</a>.</p>
<p>PyQuery as described on their page:</p>
<blockquote>
<p>allows you to make jquery queries on xml documents. The API is as much as possible the similar to jquery. pyquery uses lxml for fast xml and html manipulation.</p>
</blockquote>
<p>And it seems that there is more to come:</p>
<blockquote>
<p>It can be used for many purposes, one idea that I might try in the future is to use it for templating with pure http templates that you modify using pyquery. I can also be used for web scrapping or for theming applications with <a href="https://pythonhosted.org/Deliverance/">Deliverance</a>.</p>
</blockquote>
<h2 id="Links">Links</h2>
<ul>
<li><a href="http://localhost">Source code</a></li>
<li><a href="https://pythonhosted.org/pyquery/index.html">PyQuery docs</a></li>
<li><a href="https://pythonhosted.org/pyquery/index.html">Requests</a></li>
<li><a href="http://scrapy.org">Scrapy</a></li>
<li><a href="http://blog.miguelgrinberg.com/post/easy-web-scraping-with-python">Scraping Tutorial</a></li>
</ul>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>@Marcwebbie</h4>
    <p>A developer, emacs user, free software enthusiast. Spends his time with his family and friends or as a consultant at ThoughtWorks. Likes chess, games and coding.</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-sina-weibo" href="http://v.t.sina.com.cn/share/share.php?title=A developer, emacs user, free software enthusiast. Spends his time with his family and friends or as a consultant at ThoughtWorks. Likes chess, games and coding. ?url=http://marcwebbie.io/2015/01/06/scrap-the-web-with-PyQuery/" target="_blank">
        <span class="hidden">weibo</span>
    </a>
    <a class="icon-twitter" href="http://twitter.com/share?url=http://marcwebbie.io/2015/01/06/scrap-the-web-with-PyQuery/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://marcwebbie.io/2015/01/06/scrap-the-web-with-PyQuery/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=http://marcwebbie.io/2015/01/06/scrap-the-web-with-PyQuery/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>

    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2015/01/13/why-are-your-not-using-python/">
        ← Why Are You Still Not Using Python?
    </a>
    
    <span class="icon-logo">•</span>
    
    <a class="older-posts" href="/2014/12/29/writing-python3/">
        Write your code in Python 3 →
    </a>
    
</nav>

  <div id="comment" class="comments-area">
    <h4 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h4>
    
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
    
</div>

</main>


      
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">Marcwebbie</a> &copy; 2014 &bull; All rights reserved.</section>
  </div>
</footer>

      <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>
<script type="text/javascript" src="/js/menu.js"></script>

<script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-58207692-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
</script>


<script type="text/javascript">
    var disqus_shortname = 'marcwebbie';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>




  </div>
</div>

<nav  class="outer-nav top horizontal">

          <a class="icon-home"  href="/"><span>Home</span></a>

          <a class="icon-news"  href="/archives"><span>Archive</span></a>

          <a class="icon-github"  href="https://github.com/marcwebbie"><span>Github</span></a>

          <a class="icon-twitter"  href="https://twitter.com/marcwebbie"><span>Twitter</span></a>

</nav>

</div>
</body>
</html>
